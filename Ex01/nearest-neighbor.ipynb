{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Nearest Neighbor Classfication on Real Data\n",
    "Submission by Dominique Cheray & Jacqueline Wagner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import cross_validation\n",
    "from sklearn import neighbors\n",
    "import scipy.stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 1 Exploring the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['target_names', 'data', 'images', 'DESCR', 'target'])\n",
      "Data type: float64\n",
      "Data shape: (1797, 64)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPgAAAD8CAYAAABaQGkdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1fa3022898>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "digits = load_digits()\n",
    "print(digits.keys())\n",
    "\n",
    "data = digits[\"data\"]\n",
    "images = digits[\"images\"]\n",
    "target = digits[\"target\"]\n",
    "target_names = digits[\"target_names\"]\n",
    "\n",
    "print('Data type: ' + str(data.dtype))\n",
    "print('Data shape: ' + str(data.shape))\n",
    "\n",
    "threes = images[target==3]\n",
    "img = threes[0]\n",
    "\n",
    "assert 2 == np.size(np.shape(img))\n",
    "\n",
    "plt.figure()\n",
    "plt.gray()\n",
    "plt.imshow(img, interpolation=\"nearest\")\n",
    "plt.show()\n",
    "\n",
    "X_all = data\n",
    "Y_all = target\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = cross_validation.train_test_split(digits.data, digits.target, \n",
    "                                                                     test_size=0.4, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Distance function computation using loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dist_loop(training, test):\n",
    "    # N x D training, M x D test, D pixels per image, N training instances, M test instances, output N x M distance matrix\n",
    "    distance_matrix = np.ndarray((training.shape[0], test.shape[0]))\n",
    "    for i in range(0, training.shape[0]):\n",
    "        for j in range(0, test.shape[0]):\n",
    "            distance = 0\n",
    "            for k in range(0, test.shape[1]):\n",
    "                distance = distance + np.square(training[i][k] - test[j][k])\n",
    "            distance = np.sqrt(distance)\n",
    "            distance_matrix[i][j] = distance\n",
    "    return distance_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Distance function computation using vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dist_vec(training, test):\n",
    "    # N x D training, M x D test, D pixels per image, N training instances, M test instances, output N x M distance matrix\n",
    "    N = training.shape[0]\n",
    "    D = training.shape[1]\n",
    "    M = test.shape[0]\n",
    "    # replicate the training set along a third dimension (third dimension has the size of the nr of test instances)\n",
    "    training_3D = np.resize(training, (M, N, D))\n",
    "    # replicate the test set along a third dimens (third dimension has the size of the nr of trainig instances)\n",
    "    test_3D = np.resize(test, (N, M , D))\n",
    "    # morph 3D training matrix tho it has the same shape as the 3d trainig matrix\n",
    "    training_3D_transposed = np.transpose(training_3D, (1, 0, 2))\n",
    "    # for each entry in the 3D test and training matrices calculate the square of the distance of these entries\n",
    "    dist_mat = np.square(training_3D_transposed - test_3D)\n",
    "    # to get the sum of the squares of the corresponding test and training instances sum the matrix along the axis\n",
    "    # of the pixels of the images\n",
    "    dist_mat = np.sum(dist_mat, axis=2)\n",
    "    # finally calculate the squarerot of each entry in the distance matrix to get the euclidean distance\n",
    "    dist_mat = np.sqrt(dist_mat)\n",
    "    return dist_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 21s, sys: 12 ms, total: 1min 21s\n",
      "Wall time: 1min 21s\n",
      "CPU times: user 200 ms, sys: 356 ms, total: 556 ms\n",
      "Wall time: 556 ms\n"
     ]
    }
   ],
   "source": [
    "%time dist_mat_loop = dist_loop(X_train, X_test)\n",
    "%time dist_mat_vec = dist_vec(X_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# substract the entrys of the two distance matrices obtained by the two different methods\n",
    "dist_mat_equal = dist_mat_vec - dist_mat_loop\n",
    "# test if all entrys in the resulting matrix are zero (should be the case if both methods calculate the same distances)\n",
    "all_zeros = not np.any(dist_mat_equal)\n",
    "print(all_zeros)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Implement the nearest neighbor classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# NN classifier given training data and according labels preditcs the classes of the test data\n",
    "def nn_classifier(training_data, training_labels, test_data):\n",
    "    # use the fast method to compute the distance matrix, otherwise I would drink to much coffee while waiting \n",
    "    # for the slow method to finish\n",
    "    distance_matrix = dist_vec(training_data, test_data)\n",
    "    # get the indices of the training instances that are closest to the test instances\n",
    "    indices_min = np.argmin(distance_matrix, axis=0)\n",
    "    predicted_labels = []\n",
    "    # for each of the test instances give it the same class as the training instance closest to it\n",
    "    for i in indices_min:\n",
    "        predicted_labels.append(training_labels[i])\n",
    "    return predicted_labels\n",
    "\n",
    "# helper method to calculate the classification error given predicted labels and true labels\n",
    "def calculate_error(predicted_labels, true_labels):\n",
    "    error = 0\n",
    "    for i in range(0, len(predicted_labels)):\n",
    "        if predicted_labels[i] != true_labels[i]:\n",
    "            error = error + 1\n",
    "    error = error / len(predicted_labels)\n",
    "    return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for digits 1 and 3: 0.0\n"
     ]
    }
   ],
   "source": [
    "# test the classifier for digits 1 and 3, use the test and training partitions obtained in 2.1 and filter them \n",
    "mask_train = (Y_train == 1) | (Y_train == 3)\n",
    "mask_test = (Y_test == 1) | (Y_test == 3)\n",
    "\n",
    "Y_train_13 = Y_train[mask_train]\n",
    "Y_test_13 = Y_test[mask_test]\n",
    "X_train_13 = X_train[mask_train]\n",
    "X_test_13 = X_test[mask_test]\n",
    "\n",
    "Y_test_13_predicted = nn_classifier(X_train_13, Y_train_13, X_test_13)\n",
    "\n",
    "print('Error for digits 1 and 3: ' + str(calculate_error(Y_test_13_predicted, Y_test_13)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for digits 1 and 7: 0.0\n"
     ]
    }
   ],
   "source": [
    "# test the classifier for digits 1 and 7, use the test and training partitions obtained in 2.1 and filter them \n",
    "mask_train = (Y_train == 1) | (Y_train == 7)\n",
    "mask_test = (Y_test == 1) | (Y_test == 7)\n",
    "\n",
    "Y_train_17 = Y_train[mask_train]\n",
    "Y_test_17 = Y_test[mask_test]\n",
    "X_train_17 = X_train[mask_train]\n",
    "X_test_17 = X_test[mask_test]\n",
    "\n",
    "Y_test_17_predicted = nn_classifier(X_train_17, Y_train_17, X_test_17)\n",
    "\n",
    "print('Error for digits 1 and 7: ' + str(calculate_error(Y_test_17_predicted, Y_test_17)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for whole data: 0.012517385257301807\n"
     ]
    }
   ],
   "source": [
    "Y_predicted = nn_classifier(X_train, Y_train, X_test)\n",
    "print('Error for whole data: ' + str(calculate_error(Y_predicted, Y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Generalize to k-nearest neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# give the classifier the training instances, their labels, the test instances and the number of neighbors\n",
    "# and it will predict you the classes of the training instances\n",
    "def k_nn_classifier(training_data, training_labels, test_data, k):\n",
    "    # use once again the fast method to compute the distance matrix (too much coffe is bad, you know)\n",
    "    distance_matrix = dist_vec(training_data, test_data)\n",
    "    # get the indices of the k nearest training instances for each test instance\n",
    "    distance_matrix_indices = np.argpartition(distance_matrix, k, axis=0)[:k,:]\n",
    "    # from the indices of the closest training instances for each test instance get the classes of the training instances\n",
    "    # and then do a majority vote to get the class that occures most, this is then the class for the test instance\n",
    "    # use fancy python array stuff, because (you know it already) for loops are evil\n",
    "    predicted_labels = scipy.stats.mode(training_labels[distance_matrix_indices], axis=0)[0][0]\n",
    "    return predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for digits 3 and 9 and k=1: 0.013888888888888888\n",
      "Error for digits 3 and 9 and k=3: 0.006944444444444444\n",
      "Error for digits 3 and 9 and k=5: 0.006944444444444444\n",
      "Error for digits 3 and 9 and k=9: 0.006944444444444444\n",
      "Error for digits 3 and 9 and k=17: 0.006944444444444444\n",
      "Error for digits 3 and 9 and k=33: 0.020833333333333332\n"
     ]
    }
   ],
   "source": [
    "# now use the k nn classifier from above and test it on the digits 3 and 9 (not 1 and 7 because there it makes no error)\n",
    "# use the train and test partition form 2.1 and filter them\n",
    "# use k = 1, 3, 5, 9, 17, 33\n",
    "mask_train = (Y_train == 3) | (Y_train == 9)\n",
    "mask_test = (Y_test == 3) | (Y_test == 9)\n",
    "\n",
    "Y_train_39 = Y_train[mask_train]\n",
    "Y_test_39 = Y_test[mask_test]\n",
    "X_train_39 = X_train[mask_train]\n",
    "X_test_39 = X_test[mask_test]\n",
    "\n",
    "predicted_labels_k1 = k_nn_classifier(X_train_39, Y_train_39, X_test_39, 1)\n",
    "print('Error for digits 3 and 9 and k=1: ' +str(calculate_error(predicted_labels_k1, Y_test_39)))\n",
    "\n",
    "predicted_labels_k3 = k_nn_classifier(X_train_39, Y_train_39, X_test_39, 3)\n",
    "print('Error for digits 3 and 9 and k=3: ' +str(calculate_error(predicted_labels_k3, Y_test_39)))\n",
    "\n",
    "predicted_labels_k5 = k_nn_classifier(X_train_39, Y_train_39, X_test_39, 5)\n",
    "print('Error for digits 3 and 9 and k=5: ' +str(calculate_error(predicted_labels_k5, Y_test_39)))\n",
    "\n",
    "predicted_labels_k9 = k_nn_classifier(X_train_39, Y_train_39, X_test_39, 9)\n",
    "print('Error for digits 3 and 9 and k=9: ' +str(calculate_error(predicted_labels_k9, Y_test_39)))\n",
    "\n",
    "predicted_labels_k17 = k_nn_classifier(X_train_39, Y_train_39, X_test_39, 17)\n",
    "print('Error for digits 3 and 9 and k=17: ' +str(calculate_error(predicted_labels_k17, Y_test_39)))\n",
    "\n",
    "predicted_labels_k33 = k_nn_classifier(X_train_39, Y_train_39, X_test_39, 33)\n",
    "print('Error for digits 3 and 9 and k=33: ' +str(calculate_error(predicted_labels_k33, Y_test_39)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using more than one k the classifier performs better but there is no difference in performance between k=3, k=5, k=9 and k=17. Chossing a k too big (in this case k=33) decreases the performance of the classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# given array of features and labels this methods splits them in n parts of roughly equal size\n",
    "# actually numpy does the work for me, but the assignment said we have write a method so we did\n",
    "def split_n_folds(features, labels, n):\n",
    "    return np.array_split(features,n), np.array_split(labels,n)\n",
    "\n",
    "# cross validate the k nn classifier from above and the k nn classifier from sklearn\n",
    "# as input give the full featureset and the corresponding annotations\n",
    "# n determines in how many folds the set is splitted for the cross validation\n",
    "# then perform cross validation as describend in the assignment\n",
    "# will print mean error and standard deviation of error for both of the classifiers\n",
    "def cross_validate(features, labels, n):\n",
    "    # create the k nn classifier from sklearn\n",
    "    sklearn_nn_classifier = neighbors.KNeighborsClassifier(n_neighbors=1, p=2)\n",
    "    splitted_features, splitted_labels = split_n_folds(features, labels, n)\n",
    "    error_own = []\n",
    "    error_sklearn = []\n",
    "    for i in range(n):\n",
    "        # split the features and labels into n folds\n",
    "        splitted_features, splitted_labels = split_n_folds(features, labels, n)\n",
    "        # determine wich fold is the test fold this time\n",
    "        test_features = splitted_features[i]\n",
    "        # flatten the test set for later use with sklearn classifier, because he cannot work with an array bigger than 2D\n",
    "        n_test = len(test_features)\n",
    "        sklearn_test_features = np.reshape(test_features, (n_test, -1))\n",
    "        # remove the test set from the full features\n",
    "        del splitted_features[i]\n",
    "        # merge the remaining features to a training set\n",
    "        training_features = np.concatenate(splitted_features)\n",
    "        # again flatten the training set for sklearn\n",
    "        n_features = len(training_features)\n",
    "        sklearn_training_features = np.reshape(training_features, (n_features, -1))\n",
    "        # get the labels for the test set\n",
    "        test_labels = splitted_labels[i]\n",
    "        # remove the labels of the test set from the remaining labels\n",
    "        del splitted_labels[i]\n",
    "        # merge the remaining labels to one set\n",
    "        training_labels = np.concatenate(splitted_labels)\n",
    "        # train the sklearn classifier\n",
    "        sklearn_nn_classifier.fit(sklearn_training_features, training_labels)\n",
    "        # use sklearn classifier to predict the labels of the test set\n",
    "        predicted_sklearn = sklearn_nn_classifier.predict(sklearn_test_features)\n",
    "        # use own classifier to predict the labels of the test set\n",
    "        predicted_own = nn_classifier(training_features, training_labels, test_features)\n",
    "        # calculate the classification error of this round for both classifiers and put them in the arrays for all errors\n",
    "        error_sklearn.append(calculate_error(predicted_sklearn, test_labels))\n",
    "        error_own.append(calculate_error(predicted_own, test_labels))\n",
    "    print('Cross Validation with n = ' +str(n))\n",
    "    print('Sklearn NN classifier \\n Mean error: ' +str(np.mean(error_sklearn)) + ' Standard Deviation: ' \n",
    "          + str(np.std(error_sklearn)))\n",
    "    print('Own NN classifier \\n Mean error: ' +str(np.mean(error_own)) + ' Standard Deviation: ' \n",
    "          + str(np.std(error_own)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation with n = 2\n",
      "Sklearn NN classifier \n",
      " Mean error: 0.040066171024 Standard Deviation: 0.00109066991039\n",
      "Own NN classifier \n",
      " Mean error: 0.915968869147 Standard Deviation: 0.00394214308896\n",
      "\n",
      "Cross Validation with n = 5\n",
      "Sklearn NN classifier \n",
      " Mean error: 0.0350495202724 Standard Deviation: 0.0128664164671\n",
      "Own NN classifier \n",
      " Mean error: 0.907059733829 Standard Deviation: 0.0177065708818\n",
      "\n",
      "Cross Validation with n = 10\n",
      "Sklearn NN classifier \n",
      " Mean error: 0.0239292364991 Standard Deviation: 0.0175860474629\n",
      "Own NN classifier \n",
      " Mean error: 0.902070142768 Standard Deviation: 0.0178949162521\n"
     ]
    }
   ],
   "source": [
    "# now do the cross-valdiation as described in the assignment\n",
    "cross_validate(digits.images, digits.target, 2)\n",
    "print()\n",
    "cross_validate(digits.images, digits.target, 5)\n",
    "print()\n",
    "cross_validate(digits.images, digits.target, 10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
